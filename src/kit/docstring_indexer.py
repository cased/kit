"""Tools for indexing and searching LLM-generated code summaries.

This module introduces two public classes:

* DocstringIndexer – builds a vector index of per-file summaries generated by
  a ``kit.Summarizer``.  The index is stored in a pluggable
  :class:`kit.vector_searcher.VectorDBBackend` (default: Chroma).

* SummarySearcher  – embeds a query and retrieves the most similar summaries
  from a DocstringIndexer backend.
"""
from __future__ import annotations

import os
from typing import Callable, List, Dict, Any, Optional

from pathlib import Path

from .vector_searcher import VectorDBBackend, ChromaDBBackend
from .repository import Repository
from .summaries import Summarizer

EmbedFn = Callable[[str], List[float]]  # str -> embedding vector

__all__ = [
    "DocstringIndexer",
    "SummarySearcher",
]


class DocstringIndexer:
    """Builds a vector index of LLM-generated docstrings (summaries).

    A thin wrapper around an existing VectorDB backend.  On ``build()``, it:
    1. walks the repository file tree,
    2. calls :py:meth:`Summarizer.summarize_file` to obtain a concise summary,
    3. embeds that summary via *embed_fn*, and
    4. stores the embedding + metadata in *backend*.

    Parameters
    ----------
    repo
        Active :py:class:`kit.repository.Repository`.
    summarizer
        Configured :py:class:`kit.summaries.Summarizer`.
    embed_fn
        Callable that converts text → embedding vector (list[float]).
    backend
        Optional vector-DB backend, defaults to :class:`ChromaDBBackend`.
    persist_dir
        Where on disk to store backend data (if backend honors persistence).
    """

    def __init__(
        self,
        repo: Repository,
        summarizer: Summarizer,
        embed_fn: EmbedFn,
        *,
        backend: Optional[VectorDBBackend] = None,
        persist_dir: Optional[str] = None,
    ) -> None:
        self.repo = repo
        self.summarizer = summarizer
        self.embed_fn = embed_fn
        self.persist_dir = persist_dir or os.path.join(".kit", "docstring_db")
        self.backend: VectorDBBackend = backend or ChromaDBBackend(self.persist_dir)

    def build(self, force: bool = False) -> None:
        """(Re)build the docstring index.

        If *force* is ``False`` and the backend already contains data we do
        nothing.  (Chroma doesn’t expose a simple count API, so callers may
        choose to always pass ``force=True``.)
        """
        file_paths: List[str] = [f["path"] for f in self.repo.get_file_tree() if not f.get("is_dir", False)]
        if not file_paths:
            return

        embeddings: List[List[float]] = []
        metadatas: List[Dict[str, Any]] = []

        for path in file_paths:
            try:
                summary = self.summarizer.summarize_file(path)
            except Exception as exc:  # pragma: no cover – keep indexing robust
                # Skip files that fail to summarise rather than abort entire index.
                continue

            emb = self.embed_fn(summary)
            embeddings.append(emb)
            metadatas.append({
                "file": path,
                "summary": summary,
            })

        if embeddings:
            self.backend.add(embeddings, metadatas)
            self.backend.persist()


class SummarySearcher:
    """Simple wrapper that queries a :class:`DocstringIndexer` backend."""

    def __init__(self, indexer: DocstringIndexer):
        self.indexer = indexer
        self.embed_fn = indexer.embed_fn

    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Return up to *top_k* hits with their metadata and distance score."""
        if top_k <= 0:
            return []
        emb = self.embed_fn(query)
        return self.indexer.backend.query(emb, top_k)
